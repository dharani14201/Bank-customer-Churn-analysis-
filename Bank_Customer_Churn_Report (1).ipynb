{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75b0a5f0",
   "metadata": {},
   "source": [
    "# Bank Customer Churn Prediction\n",
    "**Team Members:** Dharani Murugesan, Jeyshree Venkatesan, Nishanthika Murugan, Vaishnavi Uma Asokkumar, Vijay Sarathy Vivekanadan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820dd4da",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Customer retention is a key concern for banks. Predicting customer churn allows the bank to proactively engage at-risk customers and prevent revenue loss. This project uses customer data from ABC Multinational Bank to build machine learning models to predict churn.\n",
    "Dataset Source: [Kaggle - Bank Customer Churn Dataset](https://www.kaggle.com/datasets/gauravtopre/bank-customer-churn-dataset/data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af37f66",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "**Features:**\n",
    "- `customer_id`: Unique ID assigned to each customer\n",
    "- `credit_score`: Customer's credit score\n",
    "- `country`: Country of the customer\n",
    "- `gender`: Male/Female\n",
    "- `age`: Age of the customer\n",
    "- `tenure`: Years with the bank\n",
    "- `balance`: Account balance\n",
    "- `products_number`: Number of products used\n",
    "- `credit_card`: Whether the customer has a credit card (1/0)\n",
    "- `active_member`: Whether the customer is active (1/0)\n",
    "- `estimated_salary`: Estimated annual salary\n",
    "- `churn`: Target variable — 1 if customer left, 0 otherwise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42986d24",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Here we clean the dataset, handle categorical variables, and prepare the features for model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffba1b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"BankCustomerChurn.csv\")  # Replace with your dataset path\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32008c3c",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "We explore key statistics and correlations to understand the behavior of churn vs. non-churned customers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a14d634",
   "metadata": {},
   "source": [
    "## Model Building and Evaluation\n",
    "We trained the following models:\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- Support Vector Machine (SVM)\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Random Forest\n",
    "\n",
    "Each model's performance is evaluated using Accuracy, Precision, Recall, and F1-score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745b468b",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "The model achieved **86.5% accuracy** with high recall (0.97), making it suitable for identifying churners. It also helps with feature importance and handles overfitting well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449ed557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Encoding and splitting data\n",
    "le = LabelEncoder()\n",
    "df['gender'] = le.fit_transform(df['gender'])\n",
    "df['country'] = le.fit_transform(df['country'])\n",
    "\n",
    "X = df.drop(['customer_id', 'churn'], axis=1)\n",
    "y = df['churn']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60683439",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Logistic Regression is used for binary classification. It estimates the probability that a given input point belongs to a certain class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a883d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc3e5fe",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "Naive Bayes is a probabilistic model based on Bayes’ Theorem assuming feature independence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30539b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "\n",
    "print(\"Naive Bayes Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209cd4cd",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)\n",
    "SVM finds the optimal hyperplane that separates the classes. Kernels can be used to handle non-linear data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03157986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dc9e55",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN)\n",
    "KNN classifies a data point based on how its neighbors are classified. It’s simple but can be slow on large datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa00f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5d23bf",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- **Best Model:** Random Forest\n",
    "- **Recall:** 0.97 — High sensitivity in identifying churners\n",
    "- **Business Impact:** Enables proactive customer retention strategies\n",
    "\n",
    "This project demonstrates the value of predictive modeling in customer retention and emphasizes the importance of model selection based on business goals.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
